{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, InputLayer\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset shape:  (1089, 7)\nDate          object\nOpen         float64\nHigh         float64\nLow          float64\nClose        float64\nAdj Close    float64\nVolume       float64\ndtype: object\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Date         Open         High          Low        Close  \\\n",
       "0  2013-12-31  1196.400024  1212.400024  1182.000000  1201.900024   \n",
       "1  2014-01-02  1204.300049  1227.300049  1204.300049  1225.000000   \n",
       "2  2014-01-03  1221.699951  1239.000000  1221.699951  1238.400024   \n",
       "3  2014-01-06  1232.800049  1247.000000  1221.900024  1237.800049   \n",
       "4  2014-01-07  1239.300049  1242.400024  1226.300049  1229.400024   \n",
       "\n",
       "     Adj Close  Volume  \n",
       "0  1201.900024   124.0  \n",
       "1  1225.000000   209.0  \n",
       "2  1238.400024   142.0  \n",
       "3  1237.800049   127.0  \n",
       "4  1229.400024    73.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2013-12-31</td>\n      <td>1196.400024</td>\n      <td>1212.400024</td>\n      <td>1182.000000</td>\n      <td>1201.900024</td>\n      <td>1201.900024</td>\n      <td>124.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014-01-02</td>\n      <td>1204.300049</td>\n      <td>1227.300049</td>\n      <td>1204.300049</td>\n      <td>1225.000000</td>\n      <td>1225.000000</td>\n      <td>209.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014-01-03</td>\n      <td>1221.699951</td>\n      <td>1239.000000</td>\n      <td>1221.699951</td>\n      <td>1238.400024</td>\n      <td>1238.400024</td>\n      <td>142.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014-01-06</td>\n      <td>1232.800049</td>\n      <td>1247.000000</td>\n      <td>1221.900024</td>\n      <td>1237.800049</td>\n      <td>1237.800049</td>\n      <td>127.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014-01-07</td>\n      <td>1239.300049</td>\n      <td>1242.400024</td>\n      <td>1226.300049</td>\n      <td>1229.400024</td>\n      <td>1229.400024</td>\n      <td>73.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "data_csv = \"dataset.csv\"\n",
    "df = pd.read_csv(data_csv)\n",
    "print('Dataset shape: ', df.shape)\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Open  High  Low  Close  Adj Close  Volume\n127   NaN   NaN  NaN    NaN        NaN     NaN\n230   NaN   NaN  NaN    NaN        NaN     NaN\n248   NaN   NaN  NaN    NaN        NaN     NaN\n515   NaN   NaN  NaN    NaN        NaN     NaN\n535   NaN   NaN  NaN    NaN        NaN     NaN\nDataset shape:  (1081, 7)\n"
     ]
    }
   ],
   "source": [
    "# Verifying null values and deleting name from dataset\n",
    "null_columns=df.columns[df.isnull().any()]\n",
    "print(df[df.isnull().any(axis=1)][null_columns].head())\n",
    "# Drop the lines with null values\n",
    "df = df.dropna()\n",
    "# Drop Date column\n",
    "# df.pop(\"Date\")\n",
    "\n",
    "print('Dataset shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Minimum: 1046.199951\nMaximum: 1391.400024\nMean: 1239.990934614246\nMedian: 1251.0\nSD: 72.09937994027128\nSkewness: -0.5455305158449637\nKurtosis: -0.3520037164214358\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum: {}\\nMaximum: {}\\nMean: {}\\nMedian: {}\\nSD: {}\\nSkewness: {}\\nKurtosis: {}\".format(df[\"Low\"].min(), df[\"High\"].max(), \n",
    "df[\"Open\"].mean(), df[\"Open\"].median(), df[\"Open\"].std(), df[\"Open\"].skew(), df[\"Open\"].kurtosis()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg height=\"264.377944pt\" version=\"1.1\" viewBox=\"0 0 388.965625 264.377944\" width=\"388.965625pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-06-23T18:05:47.840970</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.4.2, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 264.377944 \nL 388.965625 264.377944 \nL 388.965625 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 46.965625 226.821694 \nL 381.765625 226.821694 \nL 381.765625 9.381694 \nL 46.965625 9.381694 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 62.183807 226.821694 \nL 62.183807 9.381694 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_2\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"mba4bf947a8\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.183807\" xlink:href=\"#mba4bf947a8\" y=\"226.821694\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(59.002557 241.420131)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" id=\"DejaVuSans-30\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_3\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 118.547443 226.821694 \nL 118.547443 9.381694 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"118.547443\" xlink:href=\"#mba4bf947a8\" y=\"226.821694\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 200 -->\n      <g transform=\"translate(109.003693 241.420131)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" id=\"DejaVuSans-32\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_5\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 174.91108 226.821694 \nL 174.91108 9.381694 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"174.91108\" xlink:href=\"#mba4bf947a8\" y=\"226.821694\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 400 -->\n      <g transform=\"translate(165.36733 241.420131)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" id=\"DejaVuSans-34\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_7\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 231.274716 226.821694 \nL 231.274716 9.381694 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"231.274716\" xlink:href=\"#mba4bf947a8\" y=\"226.821694\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 600 -->\n      <g transform=\"translate(221.730966 241.420131)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" id=\"DejaVuSans-36\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_9\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 287.638352 226.821694 \nL 287.638352 9.381694 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"287.638352\" xlink:href=\"#mba4bf947a8\" y=\"226.821694\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 800 -->\n      <g transform=\"translate(278.094602 241.420131)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" id=\"DejaVuSans-38\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_11\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 344.001989 226.821694 \nL 344.001989 9.381694 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"344.001989\" xlink:href=\"#mba4bf947a8\" y=\"226.821694\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 1000 -->\n      <g transform=\"translate(331.276989 241.420131)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" id=\"DejaVuSans-31\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"190.869141\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- Days -->\n     <g transform=\"translate(201.8875 255.098256)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 1259 4147 \nL 1259 519 \nL 2022 519 \nQ 2988 519 3436 956 \nQ 3884 1394 3884 2338 \nQ 3884 3275 3436 3711 \nQ 2988 4147 2022 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 1925 4666 \nQ 3281 4666 3915 4102 \nQ 4550 3538 4550 2338 \nQ 4550 1131 3912 565 \nQ 3275 0 1925 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-44\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" id=\"DejaVuSans-61\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" id=\"DejaVuSans-79\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" id=\"DejaVuSans-73\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-44\"/>\n      <use x=\"77.001953\" xlink:href=\"#DejaVuSans-61\"/>\n      <use x=\"138.28125\" xlink:href=\"#DejaVuSans-79\"/>\n      <use x=\"197.460938\" xlink:href=\"#DejaVuSans-73\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_13\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 46.965625 219.138356 \nL 381.765625 219.138356 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_14\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m59aeac71b0\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m59aeac71b0\" y=\"219.138356\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 105 -->\n      <g transform=\"translate(20.878125 222.937575)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" id=\"DejaVuSans-35\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-30\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_15\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 46.965625 189.404194 \nL 381.765625 189.404194 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_16\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m59aeac71b0\" y=\"189.404194\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 110 -->\n      <g transform=\"translate(20.878125 193.203413)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_17\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 46.965625 159.670031 \nL 381.765625 159.670031 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_18\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m59aeac71b0\" y=\"159.670031\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 115 -->\n      <g transform=\"translate(20.878125 163.46925)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_19\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 46.965625 129.935869 \nL 381.765625 129.935869 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_20\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m59aeac71b0\" y=\"129.935869\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 120 -->\n      <g transform=\"translate(20.878125 133.735088)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_21\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 46.965625 100.201706 \nL 381.765625 100.201706 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_22\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m59aeac71b0\" y=\"100.201706\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 125 -->\n      <g transform=\"translate(20.878125 104.000925)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-32\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_23\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 46.965625 70.467544 \nL 381.765625 70.467544 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_24\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m59aeac71b0\" y=\"70.467544\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 130 -->\n      <g transform=\"translate(20.878125 74.266763)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" id=\"DejaVuSans-33\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_25\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 46.965625 40.733381 \nL 381.765625 40.733381 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_26\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m59aeac71b0\" y=\"40.733381\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 135 -->\n      <g transform=\"translate(20.878125 44.5326)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-33\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_27\">\n      <path clip-path=\"url(#pdd037dc897)\" d=\"M 46.965625 10.999219 \nL 381.765625 10.999219 \n\" style=\"fill:none;stroke:#b0b0b0;stroke-linecap:square;stroke-width:0.8;\"/>\n     </g>\n     <g id=\"line2d_28\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"46.965625\" xlink:href=\"#m59aeac71b0\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 140 -->\n      <g transform=\"translate(20.878125 14.798438)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-34\"/>\n       <use x=\"127.246094\" xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- Price (*10^-1) -->\n     <g transform=\"translate(14.798438 153.827475)rotate(-90)scale(0.1 -0.1)\">\n      <defs>\n       <path d=\"M 1259 4147 \nL 1259 2394 \nL 2053 2394 \nQ 2494 2394 2734 2622 \nQ 2975 2850 2975 3272 \nQ 2975 3691 2734 3919 \nQ 2494 4147 2053 4147 \nL 1259 4147 \nz\nM 628 4666 \nL 2053 4666 \nQ 2838 4666 3239 4311 \nQ 3641 3956 3641 3272 \nQ 3641 2581 3239 2228 \nQ 2838 1875 2053 1875 \nL 1259 1875 \nL 1259 0 \nL 628 0 \nL 628 4666 \nz\n\" id=\"DejaVuSans-50\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" id=\"DejaVuSans-72\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" id=\"DejaVuSans-69\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" id=\"DejaVuSans-63\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" id=\"DejaVuSans-65\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 1984 4856 \nQ 1566 4138 1362 3434 \nQ 1159 2731 1159 2009 \nQ 1159 1288 1364 580 \nQ 1569 -128 1984 -844 \nL 1484 -844 \nQ 1016 -109 783 600 \nQ 550 1309 550 2009 \nQ 550 2706 781 3412 \nQ 1013 4119 1484 4856 \nL 1984 4856 \nz\n\" id=\"DejaVuSans-28\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 3009 3897 \nL 1888 3291 \nL 3009 2681 \nL 2828 2375 \nL 1778 3009 \nL 1778 1831 \nL 1422 1831 \nL 1422 3009 \nL 372 2375 \nL 191 2681 \nL 1313 3291 \nL 191 3897 \nL 372 4206 \nL 1422 3572 \nL 1422 4750 \nL 1778 4750 \nL 1778 3572 \nL 2828 4206 \nL 3009 3897 \nz\n\" id=\"DejaVuSans-2a\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 2988 4666 \nL 4684 2925 \nL 4056 2925 \nL 2681 4159 \nL 1306 2925 \nL 678 2925 \nL 2375 4666 \nL 2988 4666 \nz\n\" id=\"DejaVuSans-5e\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 313 2009 \nL 1997 2009 \nL 1997 1497 \nL 313 1497 \nL 313 2009 \nz\n\" id=\"DejaVuSans-2d\" transform=\"scale(0.015625)\"/>\n       <path d=\"M 513 4856 \nL 1013 4856 \nQ 1481 4119 1714 3412 \nQ 1947 2706 1947 2009 \nQ 1947 1309 1714 600 \nQ 1481 -109 1013 -844 \nL 513 -844 \nQ 928 -128 1133 580 \nQ 1338 1288 1338 2009 \nQ 1338 2731 1133 3434 \nQ 928 4138 513 4856 \nz\n\" id=\"DejaVuSans-29\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-50\"/>\n      <use x=\"58.552734\" xlink:href=\"#DejaVuSans-72\"/>\n      <use x=\"99.666016\" xlink:href=\"#DejaVuSans-69\"/>\n      <use x=\"127.449219\" xlink:href=\"#DejaVuSans-63\"/>\n      <use x=\"182.429688\" xlink:href=\"#DejaVuSans-65\"/>\n      <use x=\"243.953125\" xlink:href=\"#DejaVuSans-20\"/>\n      <use x=\"275.740234\" xlink:href=\"#DejaVuSans-28\"/>\n      <use x=\"314.753906\" xlink:href=\"#DejaVuSans-2a\"/>\n      <use x=\"364.753906\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"428.376953\" xlink:href=\"#DejaVuSans-30\"/>\n      <use x=\"492\" xlink:href=\"#DejaVuSans-5e\"/>\n      <use x=\"575.789062\" xlink:href=\"#DejaVuSans-2d\"/>\n      <use x=\"611.873047\" xlink:href=\"#DejaVuSans-31\"/>\n      <use x=\"675.496094\" xlink:href=\"#DejaVuSans-29\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_29\">\n    <path clip-path=\"url(#pdd037dc897)\" d=\"M 62.183807 132.076714 \nL 62.465625 127.378702 \nL 63.029261 110.430229 \nL 63.31108 106.564788 \nL 63.592898 113.582079 \nL 63.874716 114.593012 \nL 64.156534 109.121955 \nL 64.438352 99.844911 \nL 64.72017 99.607023 \nL 65.001989 104.305035 \nL 65.283807 106.564788 \nL 65.565625 106.326973 \nL 65.847443 96.395719 \nL 66.129261 105.137606 \nL 66.41108 109.003048 \nL 66.692898 95.265806 \nL 66.974716 94.373781 \nL 67.256534 95.503694 \nL 67.82017 90.092091 \nL 68.101989 104.007693 \nL 68.383807 104.721285 \nL 68.665625 95.206353 \nL 68.947443 97.822973 \nL 69.229261 95.44424 \nL 69.51108 95.265806 \nL 69.792898 88.545929 \nL 70.074716 85.929308 \nL 70.356534 76.117035 \nL 70.638352 74.451892 \nL 70.92017 69.456611 \nL 71.201989 56.849283 \nL 71.483807 59.584811 \nL 71.765625 64.104462 \nL 72.047443 58.573879 \nL 72.329261 56.016712 \nL 72.61108 48.821059 \nL 72.892898 45.966623 \nL 73.174716 53.043295 \nL 73.456534 52.745954 \nL 73.738352 49.118401 \nL 74.02017 40.495494 \nL 74.301989 49.772538 \nL 74.583807 47.86958 \nL 74.865625 41.030723 \nL 75.147443 49.058947 \nL 75.429261 46.680214 \nL 75.71108 41.26861 \nL 75.992898 30.742674 \nL 76.556534 19.26533 \nL 76.838352 35.202798 \nL 77.12017 36.511144 \nL 77.401989 50.426747 \nL 77.683807 47.215443 \nL 77.965625 50.842997 \nL 78.247443 61.249953 \nL 78.529261 61.428388 \nL 78.81108 73.619394 \nL 79.092898 75.106102 \nL 79.374716 73.857209 \nL 79.656534 79.328338 \nL 79.938352 82.242301 \nL 80.22017 75.938601 \nL 80.501989 79.090451 \nL 80.783807 69.634973 \nL 81.065625 72.489481 \nL 81.347443 64.818053 \nL 81.629261 63.450252 \nL 81.91108 59.168562 \nL 82.192898 58.514425 \nL 82.474716 56.968263 \nL 82.756534 68.861928 \nL 83.038352 70.40809 \nL 83.32017 76.414376 \nL 83.601989 76.890152 \nL 83.883807 79.804042 \nL 84.165625 79.62568 \nL 84.729261 67.25624 \nL 85.01108 73.143618 \nL 85.292898 72.846277 \nL 85.574716 77.187494 \nL 85.856534 84.323693 \nL 86.138352 67.137332 \nL 86.42017 64.877507 \nL 86.701989 64.342277 \nL 86.983807 75.522351 \nL 87.547443 81.112388 \nL 87.829261 73.143618 \nL 88.11108 74.749234 \nL 88.392898 68.980836 \nL 88.674716 74.451892 \nL 88.956534 74.214077 \nL 89.52017 77.960538 \nL 89.801989 73.916736 \nL 90.365625 75.284464 \nL 90.647443 94.671123 \nL 90.929261 95.265806 \nL 91.21108 97.168836 \nL 91.774716 103.710352 \nL 92.056534 103.115668 \nL 92.338352 103.769806 \nL 92.62017 98.179769 \nL 92.901989 98.596091 \nL 93.183807 98.774452 \nL 93.465625 94.314328 \nL 93.747443 94.254874 \nL 94.029261 86.821333 \nL 94.31108 82.480116 \nL 94.592898 86.642899 \nL 94.874716 88.367495 \nL 95.156534 84.026351 \nL 95.438352 57.741308 \nL 95.72017 63.152911 \nL 96.001989 61.190499 \nL 96.283807 61.368861 \nL 96.565625 58.811766 \nL 97.129261 61.368861 \nL 97.41108 54.58953 \nL 97.692898 54.530004 \nL 97.974716 59.346996 \nL 98.256534 59.525358 \nL 98.82017 52.329705 \nL 99.101989 47.929034 \nL 99.383807 50.961904 \nL 99.665625 66.066873 \nL 99.947443 71.419023 \nL 100.229261 68.62404 \nL 100.51108 56.968263 \nL 100.792898 63.926028 \nL 101.074716 66.83999 \nL 101.356534 67.791469 \nL 101.638352 71.954252 \nL 101.92017 73.559868 \nL 102.201989 66.066873 \nL 102.483807 63.985482 \nL 102.765625 71.300115 \nL 103.047443 73.381506 \nL 103.329261 79.923022 \nL 103.61108 73.797756 \nL 103.892898 77.603743 \nL 104.174716 77.544289 \nL 104.456534 67.315693 \nL 104.738352 64.044936 \nL 105.301989 66.780537 \nL 105.865625 63.450252 \nL 106.147443 63.509779 \nL 106.429261 69.634973 \nL 106.992898 73.203072 \nL 107.274716 76.414376 \nL 107.556534 84.739942 \nL 107.838352 83.966824 \nL 108.12017 76.771172 \nL 108.401989 81.469184 \nL 108.683807 79.685134 \nL 108.965625 76.711718 \nL 109.247443 79.685134 \nL 109.529261 90.50834 \nL 109.81108 89.081159 \nL 110.092898 92.351917 \nL 110.374716 89.25952 \nL 110.656534 102.104664 \nL 110.938352 96.217358 \nL 111.22017 107.694701 \nL 111.501989 113.879421 \nL 111.783807 114.057855 \nL 112.065625 107.159471 \nL 112.347443 108.408364 \nL 112.629261 120.302029 \nL 112.91108 119.053136 \nL 113.192898 121.075074 \nL 113.474716 117.447521 \nL 113.756534 118.874775 \nL 114.038352 124.286378 \nL 114.32017 121.550849 \nL 114.601989 120.242503 \nL 114.883807 121.134528 \nL 115.165625 125.356837 \nL 115.447443 120.837186 \nL 115.729261 122.561782 \nL 116.01108 137.250502 \nL 116.292898 124.524266 \nL 116.574716 123.870129 \nL 116.856534 115.722925 \nL 117.138352 115.960812 \nL 117.983807 103.94824 \nL 118.265625 104.899718 \nL 118.547443 107.694701 \nL 118.829261 107.754154 \nL 119.11108 99.607023 \nL 119.392898 103.29403 \nL 119.674716 113.284738 \nL 119.956534 112.452167 \nL 120.238352 111.976464 \nL 120.52017 115.128242 \nL 120.801989 115.485037 \nL 121.365625 130.173756 \nL 121.647443 149.917212 \nL 121.929261 149.61987 \nL 122.21108 148.906279 \nL 122.492898 164.962727 \nL 122.774716 165.676318 \nL 123.056534 147.181683 \nL 123.338352 156.696615 \nL 123.62017 152.236491 \nL 123.901989 151.5229 \nL 124.183807 156.577708 \nL 124.465625 139.98603 \nL 124.747443 131.660465 \nL 125.029261 132.01726 \nL 125.31108 134.812242 \nL 125.592898 135.288018 \nL 125.874716 131.303669 \nL 126.156534 131.660465 \nL 126.438352 129.638527 \nL 126.72017 153.723199 \nL 127.001989 122.621236 \nL 127.283807 131.065781 \nL 127.565625 125.059495 \nL 127.847443 128.092365 \nL 128.129261 135.525906 \nL 128.41108 128.746502 \nL 128.692898 111.381781 \nL 128.974716 114.117309 \nL 129.256534 113.403645 \nL 129.538352 116.1987 \nL 129.82017 131.601011 \nL 130.101989 131.006328 \nL 130.383807 136.061135 \nL 130.665625 131.125235 \nL 130.947443 131.125235 \nL 131.229261 142.245783 \nL 131.51108 143.494676 \nL 131.792898 137.964093 \nL 132.074716 140.996963 \nL 132.356534 130.411645 \nL 132.638352 139.450801 \nL 132.92017 141.6511 \nL 133.483807 118.51798 \nL 133.765625 125.773086 \nL 134.047443 123.334899 \nL 134.61108 106.624315 \nL 134.892898 112.333259 \nL 135.174716 111.203346 \nL 135.738352 83.015346 \nL 136.02017 73.322053 \nL 136.301989 74.511419 \nL 136.583807 70.586451 \nL 137.147443 84.026351 \nL 137.429261 78.852563 \nL 137.71108 80.398725 \nL 137.992898 95.44424 \nL 138.274716 79.923022 \nL 138.838352 93.065507 \nL 139.12017 87.237582 \nL 139.401989 91.281458 \nL 139.683807 107.635247 \nL 139.965625 107.635247 \nL 140.247443 110.132887 \nL 140.529261 119.291024 \nL 141.092898 113.463172 \nL 141.374716 125.713632 \nL 141.656534 120.123595 \nL 141.938352 126.070428 \nL 142.22017 129.162751 \nL 142.501989 127.913931 \nL 143.065625 127.08136 \nL 143.347443 125.356837 \nL 143.629261 121.431869 \nL 143.91108 129.043844 \nL 144.192898 127.08136 \nL 144.474716 128.924936 \nL 144.756534 132.909285 \nL 145.038352 148.133162 \nL 145.32017 149.917212 \nL 145.601989 152.533832 \nL 145.883807 156.458728 \nL 146.165625 154.793658 \nL 146.447443 153.901633 \nL 147.01108 160.443149 \nL 147.292898 146.824887 \nL 147.574716 147.181683 \nL 147.856534 140.878055 \nL 148.42017 134.395993 \nL 148.701989 131.006328 \nL 148.983807 131.719919 \nL 149.265625 131.125235 \nL 149.547443 138.380342 \nL 149.829261 140.104938 \nL 150.11108 127.557136 \nL 150.674716 121.134528 \nL 151.52017 132.433509 \nL 151.801989 125.118949 \nL 152.083807 130.64946 \nL 152.365625 133.147173 \nL 152.647443 127.378702 \nL 152.929261 129.816961 \nL 153.21108 126.546203 \nL 153.492898 133.979744 \nL 153.774716 130.471098 \nL 154.056534 137.547844 \nL 154.338352 134.514901 \nL 154.62017 140.461733 \nL 155.183807 123.275446 \nL 155.465625 128.092365 \nL 155.747443 142.959446 \nL 156.029261 143.316242 \nL 156.592898 133.206627 \nL 156.874716 140.937509 \nL 157.156534 139.86705 \nL 157.72017 133.147173 \nL 158.001989 134.277086 \nL 158.283807 121.312962 \nL 158.565625 118.934229 \nL 158.847443 115.366129 \nL 159.129261 115.722925 \nL 159.41108 126.902999 \nL 159.692898 127.259794 \nL 159.974716 123.037557 \nL 160.256534 133.741856 \nL 160.538352 138.320888 \nL 161.101989 137.190975 \nL 161.383807 135.525906 \nL 161.665625 136.477385 \nL 161.947443 133.563422 \nL 162.792898 148.073708 \nL 163.356534 144.148813 \nL 163.638352 139.926577 \nL 163.92017 141.591646 \nL 164.201989 141.888988 \nL 164.483807 137.964093 \nL 164.765625 143.256788 \nL 165.047443 139.807596 \nL 165.329261 130.114303 \nL 165.61108 131.244143 \nL 165.892898 139.569708 \nL 166.174716 143.851471 \nL 166.456534 144.327174 \nL 166.738352 147.479025 \nL 167.02017 138.796664 \nL 167.301989 144.029833 \nL 167.583807 145.932863 \nL 167.865625 149.917212 \nL 168.147443 147.122229 \nL 168.429261 149.679324 \nL 168.71108 158.123869 \nL 168.992898 156.815523 \nL 169.274716 153.663745 \nL 169.556534 154.317882 \nL 169.838352 155.388341 \nL 170.12017 157.291298 \nL 170.401989 161.929857 \nL 170.683807 163.238131 \nL 170.965625 171.325809 \nL 171.247443 191.12879 \nL 171.529261 193.566977 \nL 171.81108 190.950356 \nL 172.092898 202.13043 \nL 172.374716 189.404194 \nL 172.656534 191.069336 \nL 172.938352 191.545039 \nL 173.22017 191.723473 \nL 173.501989 196.718827 \nL 173.783807 192.080268 \nL 174.065625 198.264989 \nL 174.347443 197.432418 \nL 174.629261 198.681238 \nL 175.192898 193.448069 \nL 175.474716 187.144368 \nL 175.756534 185.836094 \nL 176.038352 174.953362 \nL 176.32017 181.138082 \nL 176.601989 181.197536 \nL 176.883807 178.580988 \nL 177.165625 179.294579 \nL 178.01108 151.344466 \nL 178.856534 173.228839 \nL 179.138352 174.358678 \nL 179.42017 170.909559 \nL 179.701989 169.482305 \nL 179.983807 167.222479 \nL 180.547443 175.488592 \nL 180.829261 177.629436 \nL 181.11108 175.429137 \nL 181.392898 185.062977 \nL 181.674716 182.981586 \nL 182.238352 186.728119 \nL 182.52017 183.576269 \nL 183.365625 167.044118 \nL 183.929261 172.396267 \nL 184.21108 169.779647 \nL 184.492898 159.788939 \nL 184.774716 169.660739 \nL 185.056534 170.255422 \nL 185.62017 180.365038 \nL 185.901989 182.149087 \nL 186.183807 167.34146 \nL 186.465625 167.817163 \nL 186.747443 161.097285 \nL 187.029261 164.011248 \nL 187.31108 158.718552 \nL 187.592898 156.161386 \nL 188.156534 146.349112 \nL 188.438352 139.331893 \nL 188.72017 140.342826 \nL 189.283807 148.549484 \nL 189.565625 144.267721 \nL 189.847443 150.036192 \nL 190.129261 150.036192 \nL 190.41108 150.690329 \nL 190.692898 151.047124 \nL 190.974716 144.743496 \nL 191.538352 161.156739 \nL 191.82017 166.865684 \nL 192.101989 169.601212 \nL 192.665625 184.706182 \nL 192.947443 186.31187 \nL 193.229261 196.183597 \nL 193.792898 194.518456 \nL 194.074716 197.729759 \nL 194.356534 199.454355 \nL 194.638352 194.16166 \nL 195.201989 210.812791 \nL 195.483807 202.844021 \nL 195.765625 199.573263 \nL 196.047443 207.244691 \nL 196.329261 205.341734 \nL 196.61108 207.125784 \nL 196.892898 206.828442 \nL 197.174716 215.272915 \nL 197.456534 210.455995 \nL 197.738352 208.017809 \nL 198.02017 216.521736 \nL 198.301989 211.407474 \nL 198.583807 198.383897 \nL 198.865625 206.650008 \nL 199.147443 204.211821 \nL 199.429261 205.460642 \nL 199.71108 208.552965 \nL 199.992898 204.865958 \nL 200.274716 210.455995 \nL 200.556534 210.337015 \nL 200.838352 205.698529 \nL 201.12017 216.938057 \nL 201.401989 207.125784 \nL 201.683807 202.13043 \nL 201.965625 204.568617 \nL 202.247443 204.687524 \nL 202.529261 202.546679 \nL 202.81108 201.833088 \nL 203.374716 212.061611 \nL 203.656534 211.169587 \nL 203.938352 203.914479 \nL 204.22017 200.34638 \nL 204.501989 194.399547 \nL 204.783807 182.803224 \nL 205.065625 186.014528 \nL 205.629261 200.405834 \nL 205.91108 194.459001 \nL 206.192898 198.324443 \nL 206.474716 195.469934 \nL 206.756534 189.523101 \nL 207.038352 187.263348 \nL 207.32017 190.59356 \nL 207.601989 189.820443 \nL 207.883807 180.424491 \nL 208.165625 178.818803 \nL 208.447443 174.299225 \nL 208.729261 180.840741 \nL 209.01108 179.473013 \nL 209.292898 172.574629 \nL 209.574716 172.455721 \nL 210.701989 136.655819 \nL 210.983807 136.001609 \nL 211.265625 126.605657 \nL 211.547443 101.50998 \nL 211.829261 110.251868 \nL 212.11108 132.01726 \nL 212.392898 124.226924 \nL 212.674716 111.619596 \nL 212.956534 114.41465 \nL 213.238352 125.535198 \nL 213.52017 112.095371 \nL 213.801989 106.505334 \nL 214.083807 110.668117 \nL 214.365625 118.874775 \nL 214.647443 105.851197 \nL 214.929261 110.430229 \nL 215.21108 107.100018 \nL 215.492898 92.470824 \nL 215.774716 94.373781 \nL 216.056534 89.081159 \nL 216.338352 97.525632 \nL 216.62017 100.201706 \nL 216.901989 88.308041 \nL 217.183807 96.633607 \nL 217.465625 113.106304 \nL 217.747443 112.392713 \nL 218.029261 93.362849 \nL 218.31108 95.979469 \nL 218.592898 96.514699 \nL 218.874716 103.769806 \nL 219.156534 101.569507 \nL 219.438352 121.491396 \nL 219.72017 123.097011 \nL 220.001989 119.350478 \nL 220.283807 105.315968 \nL 220.565625 114.711992 \nL 220.847443 110.727571 \nL 221.129261 117.031271 \nL 221.41108 120.777732 \nL 221.692898 111.857484 \nL 221.974716 115.187695 \nL 222.256534 105.553856 \nL 222.538352 105.256514 \nL 222.82017 94.254874 \nL 223.101989 96.336265 \nL 223.383807 111.2628 \nL 223.665625 114.652538 \nL 223.947443 106.921656 \nL 224.229261 111.143892 \nL 224.51108 96.574153 \nL 224.792898 101.569507 \nL 225.074716 101.093731 \nL 225.356534 111.143892 \nL 225.92017 101.034277 \nL 226.201989 102.639893 \nL 226.765625 75.165556 \nL 227.047443 74.808761 \nL 227.61108 80.636613 \nL 227.892898 83.19378 \nL 228.174716 78.495768 \nL 228.456534 91.222003 \nL 228.738352 90.151545 \nL 229.02017 90.092091 \nL 229.301989 87.47547 \nL 229.583807 86.642899 \nL 229.865625 86.821333 \nL 230.147443 84.502054 \nL 230.429261 101.391073 \nL 230.71108 96.276811 \nL 230.992898 99.250227 \nL 231.274716 106.148539 \nL 231.556534 118.458453 \nL 231.838352 110.549209 \nL 232.401989 122.502328 \nL 232.683807 120.599371 \nL 233.247443 124.524266 \nL 233.529261 103.531918 \nL 233.81108 103.769806 \nL 234.092898 101.62896 \nL 234.374716 92.768166 \nL 234.656534 89.735295 \nL 235.22017 81.29075 \nL 235.501989 79.62568 \nL 235.783807 72.667843 \nL 236.065625 82.182775 \nL 236.347443 77.068514 \nL 236.629261 74.095097 \nL 236.91108 90.092091 \nL 237.192898 92.232936 \nL 237.474716 98.001407 \nL 237.756534 52.627046 \nL 238.038352 61.666203 \nL 238.32017 63.569232 \nL 238.601989 61.071519 \nL 238.883807 55.897804 \nL 239.447443 35.381232 \nL 239.729261 30.742674 \nL 240.01108 34.013431 \nL 240.292898 27.828784 \nL 240.856534 45.788189 \nL 241.138352 45.847643 \nL 241.701989 54.113754 \nL 241.983807 53.519071 \nL 242.265625 52.032363 \nL 242.547443 62.855569 \nL 242.829261 52.210797 \nL 243.11108 61.131046 \nL 243.392898 61.428388 \nL 243.956534 46.977555 \nL 244.238352 50.724089 \nL 244.52017 41.446972 \nL 244.801989 39.484561 \nL 245.083807 33.359295 \nL 245.365625 38.116761 \nL 245.647443 36.213803 \nL 245.929261 52.627046 \nL 246.21108 51.556587 \nL 246.492898 43.825705 \nL 246.774716 45.728735 \nL 247.056534 48.583171 \nL 247.338352 48.761605 \nL 247.62017 45.37194 \nL 247.901989 43.409456 \nL 248.183807 39.960264 \nL 248.465625 40.673927 \nL 248.747443 50.010426 \nL 249.029261 48.464264 \nL 249.31108 48.345356 \nL 249.592898 57.741308 \nL 249.874716 56.314053 \nL 250.156534 61.547295 \nL 250.438352 57.384512 \nL 250.72017 64.342277 \nL 251.001989 67.315693 \nL 251.283807 64.758599 \nL 251.565625 56.611395 \nL 251.847443 41.68486 \nL 252.129261 43.825705 \nL 252.41108 47.572239 \nL 252.692898 54.411096 \nL 252.974716 55.83835 \nL 253.256534 59.049655 \nL 253.538352 58.15763 \nL 253.82017 63.212437 \nL 254.101989 62.43932 \nL 254.383807 62.320412 \nL 254.947443 47.512785 \nL 255.229261 48.345356 \nL 255.51108 49.534723 \nL 256.074716 58.930674 \nL 256.356534 57.860288 \nL 256.638352 58.217083 \nL 257.201989 65.947965 \nL 257.483807 87.059221 \nL 257.765625 91.103023 \nL 258.047443 97.882427 \nL 258.329261 94.909011 \nL 258.61108 99.190774 \nL 258.892898 95.027991 \nL 259.456534 100.26116 \nL 259.738352 93.719645 \nL 260.02017 92.530278 \nL 260.301989 88.308041 \nL 260.583807 90.746228 \nL 260.865625 88.783817 \nL 261.147443 91.816687 \nL 261.429261 85.929308 \nL 261.71108 88.664837 \nL 261.992898 88.129607 \nL 262.274716 84.383146 \nL 262.556534 82.777458 \nL 263.12017 72.608389 \nL 263.401989 70.467544 \nL 263.965625 79.923022 \nL 264.247443 86.999767 \nL 264.529261 85.691421 \nL 264.81108 113.403645 \nL 265.092898 115.485037 \nL 265.374716 112.51162 \nL 265.656534 115.306675 \nL 265.938352 122.859124 \nL 266.22017 124.226924 \nL 266.501989 123.751149 \nL 266.783807 122.323894 \nL 267.065625 143.613584 \nL 267.347443 137.072068 \nL 267.629261 133.979744 \nL 267.91108 137.607297 \nL 268.192898 146.170751 \nL 268.474716 146.408566 \nL 268.756534 140.759075 \nL 269.038352 147.241137 \nL 269.32017 149.144167 \nL 269.601989 145.516541 \nL 270.165625 154.734131 \nL 270.447443 151.641807 \nL 270.729261 153.842106 \nL 271.292898 173.4072 \nL 271.574716 165.97366 \nL 271.856534 169.482305 \nL 272.138352 167.936143 \nL 272.42017 170.850106 \nL 272.701989 171.028467 \nL 272.983807 169.006529 \nL 273.265625 164.903273 \nL 273.547443 163.357038 \nL 273.829261 152.533832 \nL 274.11108 156.577708 \nL 274.392898 155.923498 \nL 274.674716 146.587 \nL 274.956534 143.910925 \nL 275.238352 145.457087 \nL 275.52017 139.272367 \nL 275.801989 137.369409 \nL 276.083807 134.277086 \nL 276.365625 132.493036 \nL 276.929261 121.848191 \nL 277.21108 129.638527 \nL 277.492898 128.270727 \nL 278.056534 118.636887 \nL 278.338352 128.746502 \nL 278.62017 130.114303 \nL 278.901989 137.131522 \nL 279.465625 132.968739 \nL 279.747443 122.859124 \nL 280.029261 124.16747 \nL 280.592898 116.912291 \nL 280.874716 109.597731 \nL 281.156534 110.846551 \nL 281.438352 106.505334 \nL 281.72017 113.522625 \nL 282.001989 111.79803 \nL 282.283807 114.533558 \nL 282.565625 114.771446 \nL 283.129261 105.73229 \nL 283.41108 107.754154 \nL 283.692898 108.467818 \nL 283.974716 108.467818 \nL 284.256534 100.201706 \nL 284.538352 97.406724 \nL 284.82017 98.060861 \nL 285.101989 101.50998 \nL 285.383807 101.866849 \nL 285.665625 111.084439 \nL 285.947443 109.003048 \nL 286.792898 127.259794 \nL 287.074716 132.195694 \nL 287.356534 126.248862 \nL 287.638352 128.092365 \nL 287.92017 131.006328 \nL 288.201989 116.73393 \nL 288.483807 113.819967 \nL 288.765625 112.51162 \nL 289.047443 114.236217 \nL 289.329261 101.450527 \nL 289.61108 102.342552 \nL 289.892898 101.391073 \nL 290.174716 96.752514 \nL 290.456534 96.693061 \nL 290.738352 98.893432 \nL 291.02017 98.358202 \nL 291.301989 104.899718 \nL 291.865625 98.358202 \nL 292.147443 96.990402 \nL 292.429261 96.574153 \nL 292.71108 100.499048 \nL 292.992898 98.596091 \nL 293.274716 97.525632 \nL 293.556534 85.334625 \nL 294.12017 75.343917 \nL 294.401989 80.04193 \nL 294.683807 77.603743 \nL 294.965625 82.539643 \nL 295.247443 82.480116 \nL 295.529261 85.334625 \nL 295.81108 84.977829 \nL 296.092898 90.686774 \nL 296.374716 90.270525 \nL 296.656534 90.746228 \nL 296.938352 89.081159 \nL 297.22017 96.514699 \nL 297.501989 97.168836 \nL 298.065625 113.879421 \nL 298.347443 115.663471 \nL 298.629261 114.41465 \nL 298.91108 118.161111 \nL 299.192898 118.934229 \nL 299.474716 113.284738 \nL 299.756534 113.582079 \nL 300.038352 111.857484 \nL 300.601989 97.347198 \nL 300.883807 98.596091 \nL 301.165625 99.190774 \nL 301.447443 93.362849 \nL 301.729261 99.071794 \nL 302.01108 95.979469 \nL 302.292898 89.735295 \nL 302.574716 89.854203 \nL 302.856534 92.82762 \nL 303.138352 89.497408 \nL 303.42017 91.16255 \nL 303.701989 82.836985 \nL 303.983807 82.718004 \nL 304.265625 75.462897 \nL 304.829261 83.610029 \nL 305.11108 90.448887 \nL 305.392898 91.816687 \nL 305.674716 88.664837 \nL 305.956534 92.351917 \nL 306.238352 98.536564 \nL 306.52017 98.952886 \nL 306.801989 104.840265 \nL 307.083807 103.710352 \nL 307.365625 99.607023 \nL 307.647443 100.201706 \nL 307.929261 94.135966 \nL 308.21108 99.250227 \nL 308.492898 101.093731 \nL 308.774716 101.272165 \nL 309.056534 103.94824 \nL 309.338352 116.555496 \nL 309.62017 115.009334 \nL 310.465625 124.762154 \nL 310.747443 119.053136 \nL 311.029261 117.209633 \nL 311.31108 121.075074 \nL 311.592898 112.154825 \nL 312.156534 105.910651 \nL 312.438352 108.170476 \nL 312.72017 99.785457 \nL 313.001989 96.633607 \nL 313.283807 98.596091 \nL 313.565625 103.29403 \nL 313.847443 94.492761 \nL 314.129261 95.206353 \nL 314.41108 88.962179 \nL 314.692898 89.25952 \nL 314.974716 89.200066 \nL 315.256534 90.746228 \nL 315.538352 88.902725 \nL 315.82017 95.027991 \nL 316.101989 96.098378 \nL 316.383807 94.135966 \nL 316.665625 84.383146 \nL 316.947443 78.614675 \nL 317.229261 77.365855 \nL 317.792898 87.534924 \nL 318.074716 80.101383 \nL 318.356534 77.246947 \nL 318.638352 79.268885 \nL 319.201989 76.771172 \nL 319.483807 77.187494 \nL 319.765625 79.149905 \nL 320.047443 74.332985 \nL 320.329261 59.28747 \nL 320.61108 65.59117 \nL 320.892898 66.542649 \nL 321.456534 49.534723 \nL 321.738352 46.680214 \nL 322.02017 48.821059 \nL 322.301989 40.138698 \nL 322.583807 52.032363 \nL 323.429261 58.811766 \nL 323.71108 58.217083 \nL 323.992898 64.639619 \nL 324.274716 65.769532 \nL 324.556534 63.331345 \nL 324.838352 71.002773 \nL 325.12017 73.44096 \nL 325.401989 74.570872 \nL 325.683807 67.791469 \nL 325.965625 80.339271 \nL 326.247443 80.517705 \nL 326.529261 79.863568 \nL 326.81108 85.334625 \nL 327.092898 88.486475 \nL 327.656534 83.669483 \nL 327.938352 89.735295 \nL 328.22017 82.004413 \nL 328.501989 80.815047 \nL 329.065625 75.522351 \nL 329.347443 74.451892 \nL 329.629261 69.278177 \nL 329.91108 73.381506 \nL 330.192898 82.420663 \nL 330.474716 78.555222 \nL 331.038352 85.513059 \nL 331.32017 85.037283 \nL 331.601989 88.367495 \nL 331.883807 86.22665 \nL 332.165625 89.25952 \nL 332.447443 88.308041 \nL 332.729261 86.464537 \nL 333.01108 86.999767 \nL 333.292898 85.394079 \nL 333.574716 91.103023 \nL 333.856534 88.902725 \nL 334.138352 84.264166 \nL 334.42017 84.799396 \nL 334.983807 80.279817 \nL 335.265625 83.966824 \nL 335.547443 84.204713 \nL 335.829261 81.528638 \nL 336.11108 83.847917 \nL 336.392898 77.425309 \nL 336.674716 85.572513 \nL 336.956534 81.707071 \nL 337.238352 79.566227 \nL 337.52017 74.154551 \nL 337.801989 73.619394 \nL 338.083807 74.392439 \nL 338.647443 85.869854 \nL 338.929261 86.821333 \nL 339.21108 85.096737 \nL 339.492898 91.340912 \nL 339.774716 92.887073 \nL 340.056534 102.402005 \nL 340.338352 101.153185 \nL 340.62017 105.375421 \nL 340.901989 105.018626 \nL 341.183807 98.477111 \nL 341.465625 98.358202 \nL 341.747443 96.514699 \nL 342.029261 93.600736 \nL 342.31108 93.481756 \nL 342.592898 90.448887 \nL 342.874716 90.50834 \nL 343.156534 80.933955 \nL 343.438352 79.982476 \nL 343.72017 77.484835 \nL 344.283807 69.099743 \nL 344.565625 58.573879 \nL 344.847443 58.930674 \nL 345.129261 58.395445 \nL 345.41108 58.633333 \nL 345.692898 64.758599 \nL 345.974716 58.395445 \nL 346.256534 60.298474 \nL 346.538352 53.93532 \nL 347.101989 50.010426 \nL 347.383807 53.281184 \nL 347.665625 52.567592 \nL 347.947443 53.578525 \nL 348.229261 49.177854 \nL 348.51108 37.224736 \nL 348.792898 36.986848 \nL 349.074716 39.781902 \nL 349.356534 47.453331 \nL 349.638352 48.166922 \nL 350.201989 41.625406 \nL 350.483807 51.972909 \nL 350.765625 47.750673 \nL 351.329261 60.298474 \nL 351.892898 56.314053 \nL 352.174716 55.897804 \nL 352.456534 50.961904 \nL 352.738352 39.544015 \nL 353.02017 38.354648 \nL 353.301989 41.68486 \nL 353.583807 54.530004 \nL 353.865625 57.384512 \nL 354.429261 49.65363 \nL 354.71108 51.616114 \nL 354.992898 61.309407 \nL 355.274716 64.282824 \nL 355.556534 61.963544 \nL 355.838352 56.492487 \nL 356.12017 57.6224 \nL 356.401989 47.810126 \nL 356.683807 55.71937 \nL 356.965625 60.476836 \nL 357.247443 58.930674 \nL 357.529261 55.065233 \nL 357.81108 57.265605 \nL 358.374716 64.461257 \nL 358.656534 64.877507 \nL 359.22017 63.093457 \nL 359.783807 44.777257 \nL 360.065625 41.625406 \nL 360.347443 46.085531 \nL 360.629261 43.706798 \nL 360.91108 56.195146 \nL 361.192898 54.411096 \nL 361.474716 46.442326 \nL 361.756534 51.556587 \nL 362.038352 50.545655 \nL 362.32017 54.708438 \nL 362.601989 50.842997 \nL 362.883807 49.534723 \nL 363.165625 46.62076 \nL 363.447443 40.019791 \nL 363.729261 49.118401 \nL 364.292898 41.922748 \nL 364.574716 44.598822 \nL 364.856534 41.565952 \nL 365.42017 50.248313 \nL 365.701989 54.767892 \nL 365.983807 56.195146 \nL 366.265625 61.131046 \nL 366.547443 61.368861 \nL 366.547443 61.368861 \n\" style=\"fill:none;stroke:#1f77b4;stroke-linecap:square;stroke-width:1.5;\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 46.965625 226.821694 \nL 46.965625 9.381694 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 381.765625 226.821694 \nL 381.765625 9.381694 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 46.965625 226.821694 \nL 381.765625 226.821694 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 46.965625 9.381694 \nL 381.765625 9.381694 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pdd037dc897\">\n   <rect height=\"217.44\" width=\"334.8\" x=\"46.965625\" y=\"9.381694\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "lastday_2017 = df.loc[df[\"Date\"]==\"2017-12-29\"].index.values[0]\n",
    "df = df[\"Open\"].values\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(df/10)\n",
    "plt.xlabel(\"Days\")\n",
    "plt.ylabel(\"Price (*10^-1)\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train:  (1007,) Test:  (74,)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "# Transforming the dataset to ln scale\n",
    "df = np.log(df)\n",
    "\n",
    "# # Split dataset into train and test\n",
    "train_set = df[0:lastday_2017]\n",
    "test_set = df[lastday_2017:]\n",
    "print(\"Train: \", train_set.shape, \"Test: \", test_set.shape)\n",
    "lastday_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels of an LSTM network\n",
    "Now for the labels of the LSTM network, not all the cases require a label matrix of 3 dimensions. The cases where this is required are on sequence to sequence problems, where the model is made to predict a sequence of timestamps of one or more features. However for our problem, the LSTM network needs to predict the next day gold price closing value, this way a matrix of 2 dimensions will suffice for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFNN class\n",
    "class FFNN:\n",
    "    def __init__(self, input_dim, scaler=None):\n",
    "        self.scaler = scaler \n",
    "        optimizer = Adam()\n",
    "        h_n = 3 if input_dim == 4 or input_dim == 6 else 5\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(h_n, input_dim=input_dim))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=[\"accuracy\", \"mean_absolute_error\"])\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        if self.scaler:\n",
    "            x_train = self.scaler.transform(x_train)\n",
    "            y_train = self.scaler.transform(y_train)\n",
    "        self.model.fit(x_train, y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=128,\n",
    "                        verbose=0\n",
    "                      )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        if self.scaler:\n",
    "            x_test = self.scaler.transform(x_test)\n",
    "            \n",
    "        y_valid_pred = self.model.predict(x_test)\n",
    "        \n",
    "        if self.scaler:\n",
    "            y_valid_pred = self.scaler.transform(y_valid_pred)\n",
    "\n",
    "        return y_valid_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM class\n",
    "class PLSTM:\n",
    "    def __init__(self, input_shape, model_type, scaler=None):\n",
    "        self.scaler = scaler \n",
    "        optimizer = Adam()\n",
    "        self.model = Sequential()\n",
    "        self.h_n1 = 100 if model_type in [1,3,4] else 200\n",
    "        return_seq = True if model_type>2 else False\n",
    "        self.model.add(LSTM(units=self.h_n1, input_shape=(input_shape[1], 1), return_sequences=return_seq))\n",
    "        if model_type>2:\n",
    "            self.h_n2 = 50 if model_type == 3 else 100\n",
    "            self.model.add(LSTM(units=self.h_n2))\n",
    "            if type==4:\n",
    "                self.model.add(Dense(32))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=[\"accuracy\", \"mean_absolute_error\"])\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        if self.scaler:\n",
    "            x_train = self.scaler.transform(x_train)\n",
    "            y_train = self.scaler.transform(y_train)\n",
    "\n",
    "        # reshape the entry as a 3D matrix with samples, timestamps and lastly features\n",
    "        # instead of only samples and features as usual.\n",
    "        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "        history = self.model.fit(x_train, y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=128,\n",
    "                        verbose=0)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        if self.scaler:\n",
    "            x_test = self.scaler.transform(x_test)\n",
    "            \n",
    "        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "        y_valid_pred = self.model.predict(x_test)\n",
    "        \n",
    "        if self.scaler:\n",
    "            y_valid_pred = self.scaler.transform(y_valid_pred)\n",
    "\n",
    "        return y_valid_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-LSTM class\n",
    "class CNNLSTM:\n",
    "    def __init__(self, input_shape, model_type, scaler=None):\n",
    "        self.scaler = scaler\n",
    "        optimizer = Adam()\n",
    "        self.model = Sequential()\n",
    "        self.h_n1 = 100 if model_type == 1 else 200\n",
    "        self.filter1 = 32 if model_type == 1 else 64\n",
    "        self.filter2 = 64 if model_type == 1 else 128\n",
    "        \n",
    "        self.model.add(Conv1D(self.filter1, 2,activation='relu',\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       input_shape=(input_shape[1],\n",
    "                                   1)))\n",
    "\n",
    "        self.model.add(Conv1D(self.filter2, 2,\n",
    "                   activation='relu',\n",
    "                   strides=1,\n",
    "                   padding='same',\n",
    "                   input_shape=(input_shape[1],\n",
    "                                1)))\n",
    "\n",
    "        self.model.add(MaxPooling1D(pool_size=2, padding='valid'))\n",
    "        self.model.add(LSTM(units=self.h_n1, input_shape=(input_shape[1],1)))\n",
    "    \n",
    "        if type==2:\n",
    "            self.model.add(Dense(32))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        if self.scaler:\n",
    "            x_train = self.scaler.transform(x_train)\n",
    "            y_train = self.scaler.transform(y_train)\n",
    "            \n",
    "        # reshape the entry as a 3D matrix with samples, timestamps and lastly features\n",
    "        # instead of only samples and features as usual.\n",
    "        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "        \n",
    "        self.model.fit(x_train, y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=128,\n",
    "                        verbose=0\n",
    "                      )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        if self.scaler:\n",
    "            x_test = self.scaler.transform(x_test)\n",
    "            \n",
    "        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "        y_valid_pred = self.model.predict(x_test)\n",
    "        \n",
    "        if self.scaler:\n",
    "            y_valid_pred = self.scaler.transform(y_valid_pred)\n",
    "\n",
    "        return y_valid_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(entry_shape, scaler=None):\n",
    "    # SVR\n",
    "    svr = SVR(kernel='rbf', C=1, tol=1e-3)\n",
    "\n",
    "    # FFNN\n",
    "    ffnn = FFNN(entry_shape[1], scaler)\n",
    "\n",
    "    # LSTM1\n",
    "    lstm1 = PLSTM(entry_shape, 1, scaler)\n",
    "\n",
    "    # LSTM2\n",
    "    lstm2 = PLSTM(entry_shape, 2, scaler)\n",
    "\n",
    "    # LSTM3\n",
    "    lstm3 = PLSTM(entry_shape, 3, scaler)\n",
    "\n",
    "    # LSTM4\n",
    "    lstm4 = PLSTM(entry_shape, 4, scaler)\n",
    "\n",
    "    # CNN-LSTM1\n",
    "    cnnlstm1 = CNNLSTM(entry_shape, 1, scaler)\n",
    "\n",
    "    # CNN-LSTM2\n",
    "    cnnlstm2 = CNNLSTM(entry_shape, 2, scaler)\n",
    "\n",
    "    labels = [\"SVR\", \"FFNN\", \"LSTM1\", \"LSTM2\", \"LSTM3\", \"LSTM4\", \"CNN-LSTM1\", \"CNN-LSTM2\"]\n",
    "    models = [svr, ffnn, lstm1, lstm2, lstm3, lstm4, cnnlstm1, cnnlstm2]\n",
    "\n",
    "    return labels, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling window approach\n",
    "The paper states that in order to predict the next day gold price, the model uses the $n$ past days gold prince, where $n$ stands for the time horizon used. Thus to generate a dataset with this specifications, we will use a rolling window algorithm to generate a window of features to a window of labels ( with in this case is equal to 1). This rolling window procedure works as follows:\n",
    "\n",
    "Features: $[n1, n2, n3, n4, n5]$ -> Label $[n6]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_mtx(x, window_size):\n",
    "        \"\"\"Compute all overlapping (rolling) observation windows over a vector \n",
    "            and return a matrix\n",
    "\n",
    "        Args:\n",
    "            x           : observation vector that is supposed to be split into\n",
    "                          overlapping windows\n",
    "            window_size : the target window size\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Window matrix with all windows as rows. That is, if n_windows is the\n",
    "            number of windows, the result has dimensions:\n",
    "\n",
    "            (n_windows, window_size)\n",
    "\n",
    "        \"\"\"\n",
    "        if window_size < 1:\n",
    "            raise ValueError(\"`window_size` must be at least 1.\")\n",
    "        if window_size > x.shape[-1]:\n",
    "            raise ValueError(\"`window_size` is too long.\")\n",
    "\n",
    "        shape = x.shape[:-1] + (x.shape[-1] - window_size + 1, window_size)\n",
    "        strides = x.strides + (x.strides[-1],)\n",
    "\n",
    "        return np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feat_labels_per_horizon(time_horizon, df, verbose=False):\n",
    "\n",
    "    # Get the feature and label to the prediction task \n",
    "    feature_mtx = rolling_window_mtx(df, time_horizon)[:-1]\n",
    "    label_mtx   = rolling_window_mtx(df[time_horizon:], 1)\n",
    "    index_mtx   = rolling_window_mtx(np.arange(len(df)), time_horizon)\n",
    "\n",
    "    if verbose:\n",
    "        # Now we have a set of windows of the real coordinate\n",
    "        # Lets take a look in one window\n",
    "        print(f\"\\n One feature window: \\n {feature_mtx[0]}\")\n",
    "        print(f\"\\n One label window: \\n {label_mtx[0]}\")\n",
    "        print(f\"\\n Original dataset: \\n {df[0:5]}\")\n",
    "\n",
    "    # For the classification task (if the gold values goes up or down)\n",
    "    # We need to get a window of size 2, and then calculate the difference\n",
    "    # If positive, the gold value went up.\n",
    "    class_label_mtx = rolling_window_mtx(df[time_horizon-1:], 2)\n",
    "    func = lambda x: True if x > 0 else False\n",
    "    class_func = np.vectorize(func)\n",
    "    class_label_mtx = class_func(np.diff(class_label_mtx).flatten()).reshape(len(class_label_mtx),1)\n",
    "   \n",
    "    if verbose:\n",
    "    \n",
    "        print(f\"\\n One window of class label (If tomorrow price is larger than today's price): \\n {class_label_mtx[0]}\")\n",
    "    \n",
    "    return feature_mtx, label_mtx, class_label_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index_mtx = rolling_window_mtx(np.arange(len(df))[4:], 1)\n",
    "index_mtx   = rolling_window_mtx(np.arange(len(df)), 4)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([1003, 1004, 1005, 1006]), array([1007]))"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "train_idx = lastday_2017 - 4\n",
    "index_mtx[train_idx], label_index_mtx[train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7.08707235, 7.0936538 , 7.10799857, ..., 7.18841274, 7.18212409,\n",
       "       7.18182009])"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "df = df.reshape(len(df),1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(df)\n",
    "df = df.flatten()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVR\n",
      "FFNN\n",
      "/home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "LSTM1\n",
      "LSTM2\n",
      "LSTM3\n",
      "LSTM4\n",
      "CNN-LSTM1\n",
      "CNN-LSTM2\n",
      "SVR\n",
      "FFNN\n",
      "/home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "LSTM1\n",
      "LSTM2\n",
      "LSTM3\n",
      "LSTM4\n",
      "CNN-LSTM1\n",
      "CNN-LSTM2\n",
      "SVR\n",
      "FFNN\n",
      "/home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "LSTM1\n",
      "LSTM2\n",
      "LSTM3\n",
      "LSTM4\n",
      "CNN-LSTM1\n",
      "CNN-LSTM2\n"
     ]
    }
   ],
   "source": [
    "entries = [4, 6, 9]\n",
    "models = []\n",
    "labels = []\n",
    "for entry in entries:\n",
    "    #Creating dataset\n",
    "    feature_mtx, label_mtx, class_label_mtx = generate_feat_labels_per_horizon(entry, df)\n",
    "    scaler_input = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_input.fit(feature_mtx)\n",
    "    scaler_output = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_output.fit(label_mtx)\n",
    "    train_idx = lastday_2017 - entry\n",
    "    train_x = feature_mtx[:train_idx]\n",
    "    train_y = label_mtx[:train_idx]\n",
    "    tmp_labels, tmp_models = create_models(train_x.shape)#, scaler)\n",
    "    for i in range(len(tmp_models)):\n",
    "        print(tmp_labels[i])\n",
    "        tmp_models[i].fit(train_x, train_y)\n",
    "    models.append(tmp_models)\n",
    "    labels.append(tmp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "models = np.ravel(models)\n",
    "labels = np.ravel(labels)\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_pred(y):\n",
    "    preds = []\n",
    "    for i in range(1, len(y)):\n",
    "        last_y = y[i - 1]\n",
    "        curr_y = y[i]\n",
    "        preds.append(curr_y - last_y > 0.0 )\n",
    "    return np.array(preds)\n",
    "\n",
    "# Metric functions\n",
    "def get_metrics(y, pred_y):\n",
    "    y_classification = classification_pred(y)\n",
    "    y_pred_classification = classification_pred(pred_y)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(y_classification, y_pred_classification)\n",
    "    auc_value = auc(fpr, tpr)\n",
    "\n",
    "    \n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for i in range(len(y_classification)):\n",
    "        is_y_pred_up = y_pred_classification[i]\n",
    "        is_y_up = y_classification[i][0]\n",
    "\n",
    "        if is_y_pred_up and is_y_up:\n",
    "            tp += 1\n",
    "        elif is_y_pred_up and not is_y_up:\n",
    "            fp += 1\n",
    "        elif not is_y_pred_up and not is_y_up:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    return tp, tn, fp, fn, auc_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Entries:  4\n",
      "\n",
      "Classifier type:  SVR\n",
      "MAE =  0.06545422381314349\n",
      "RMSE =  0.004345634031822117\n",
      "ACC =  0.4383561643835616\n",
      "AUC =  0.4347662141779789\n",
      "SEN =  0.48717948717948717\n",
      "SPE =  0.38235294117647056\n",
      "TP =  19\n",
      "TN =  13\n",
      "FP =  21\n",
      "FN =  20\n",
      "\n",
      "Classifier type:  FFNN\n",
      "MAE =  0.006243084452771838\n",
      "RMSE =  6.016190667923057e-05\n",
      "ACC =  0.5205479452054794\n",
      "AUC =  0.5211161387631976\n",
      "SEN =  0.5128205128205128\n",
      "SPE =  0.5294117647058824\n",
      "TP =  20\n",
      "TN =  18\n",
      "FP =  16\n",
      "FN =  19\n",
      "\n",
      "Classifier type:  LSTM1\n",
      "MAE =  0.0657593443286445\n",
      "RMSE =  0.004406134358293345\n",
      "ACC =  0.3835616438356164\n",
      "AUC =  0.3815987933634992\n",
      "SEN =  0.41025641025641024\n",
      "SPE =  0.35294117647058826\n",
      "TP =  16\n",
      "TN =  12\n",
      "FP =  22\n",
      "FN =  23\n",
      "\n",
      "Classifier type:  LSTM2\n",
      "MAE =  0.05362736338109844\n",
      "RMSE =  0.002952316078224583\n",
      "ACC =  0.3698630136986301\n",
      "AUC =  0.3687782805429864\n",
      "SEN =  0.38461538461538464\n",
      "SPE =  0.35294117647058826\n",
      "TP =  15\n",
      "TN =  12\n",
      "FP =  22\n",
      "FN =  24\n",
      "\n",
      "Classifier type:  LSTM3\n",
      "MAE =  0.07591989359556278\n",
      "RMSE =  0.005847012449624273\n",
      "ACC =  0.3835616438356164\n",
      "AUC =  0.3778280542986425\n",
      "SEN =  0.46153846153846156\n",
      "SPE =  0.29411764705882354\n",
      "TP =  18\n",
      "TN =  10\n",
      "FP =  24\n",
      "FN =  21\n",
      "\n",
      "Classifier type:  LSTM4\n",
      "MAE =  0.06863232686929062\n",
      "RMSE =  0.004791351566339322\n",
      "ACC =  0.4383561643835616\n",
      "AUC =  0.4347662141779789\n",
      "SEN =  0.48717948717948717\n",
      "SPE =  0.38235294117647056\n",
      "TP =  19\n",
      "TN =  13\n",
      "FP =  21\n",
      "FN =  20\n",
      "\n",
      "Classifier type:  CNN-LSTM1\n",
      "MAE =  0.05783713956353088\n",
      "RMSE =  0.003410030394132521\n",
      "ACC =  0.4246575342465753\n",
      "AUC =  0.42383107088989447\n",
      "SEN =  0.4358974358974359\n",
      "SPE =  0.4117647058823529\n",
      "TP =  17\n",
      "TN =  14\n",
      "FP =  20\n",
      "FN =  22\n",
      "\n",
      "Classifier type:  CNN-LSTM2\n",
      "MAE =  0.059080879078268395\n",
      "RMSE =  0.0035560343662897074\n",
      "ACC =  0.4246575342465753\n",
      "AUC =  0.42760180995475117\n",
      "SEN =  0.38461538461538464\n",
      "SPE =  0.47058823529411764\n",
      "TP =  15\n",
      "TN =  16\n",
      "FP =  18\n",
      "FN =  24\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       Model       MAE      RMSE    ACC (%)       AUC      SPEN       SPE\n0        SVR  0.065454  0.004346  43.835616  0.434766  0.487179  0.382353\n1       FFNN  0.006243  0.000060  52.054795  0.521116  0.512821  0.529412\n2      LSTM1  0.065759  0.004406  38.356164  0.381599  0.410256  0.352941\n3      LSTM2  0.053627  0.002952  36.986301  0.368778  0.384615  0.352941\n4      LSTM3  0.075920  0.005847  38.356164  0.377828  0.461538  0.294118\n5      LSTM4  0.068632  0.004791  43.835616  0.434766  0.487179  0.382353\n6  CNN-LSTM1  0.057837  0.003410  42.465753  0.423831  0.435897  0.411765\n7  CNN-LSTM2  0.059081  0.003556  42.465753  0.427602  0.384615  0.470588",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>MAE</th>\n      <th>RMSE</th>\n      <th>ACC (%)</th>\n      <th>AUC</th>\n      <th>SPEN</th>\n      <th>SPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVR</td>\n      <td>0.065454</td>\n      <td>0.004346</td>\n      <td>43.835616</td>\n      <td>0.434766</td>\n      <td>0.487179</td>\n      <td>0.382353</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FFNN</td>\n      <td>0.006243</td>\n      <td>0.000060</td>\n      <td>52.054795</td>\n      <td>0.521116</td>\n      <td>0.512821</td>\n      <td>0.529412</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LSTM1</td>\n      <td>0.065759</td>\n      <td>0.004406</td>\n      <td>38.356164</td>\n      <td>0.381599</td>\n      <td>0.410256</td>\n      <td>0.352941</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LSTM2</td>\n      <td>0.053627</td>\n      <td>0.002952</td>\n      <td>36.986301</td>\n      <td>0.368778</td>\n      <td>0.384615</td>\n      <td>0.352941</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LSTM3</td>\n      <td>0.075920</td>\n      <td>0.005847</td>\n      <td>38.356164</td>\n      <td>0.377828</td>\n      <td>0.461538</td>\n      <td>0.294118</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LSTM4</td>\n      <td>0.068632</td>\n      <td>0.004791</td>\n      <td>43.835616</td>\n      <td>0.434766</td>\n      <td>0.487179</td>\n      <td>0.382353</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>CNN-LSTM1</td>\n      <td>0.057837</td>\n      <td>0.003410</td>\n      <td>42.465753</td>\n      <td>0.423831</td>\n      <td>0.435897</td>\n      <td>0.411765</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>CNN-LSTM2</td>\n      <td>0.059081</td>\n      <td>0.003556</td>\n      <td>42.465753</td>\n      <td>0.427602</td>\n      <td>0.384615</td>\n      <td>0.470588</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Entries:  6\n",
      "\n",
      "Classifier type:  SVR\n",
      "MAE =  0.06427217056847337\n",
      "RMSE =  0.004197745836843683\n",
      "ACC =  0.4657534246575342\n",
      "AUC =  0.46040723981900444\n",
      "SEN =  0.5384615384615384\n",
      "SPE =  0.38235294117647056\n",
      "TP =  21\n",
      "TN =  13\n",
      "FP =  21\n",
      "FN =  18\n",
      "\n",
      "Classifier type:  FFNN\n",
      "MAE =  0.07698913648537949\n",
      "RMSE =  0.006036784666449123\n",
      "ACC =  0.589041095890411\n",
      "AUC =  0.5889894419306184\n",
      "SEN =  0.5897435897435898\n",
      "SPE =  0.5882352941176471\n",
      "TP =  23\n",
      "TN =  20\n",
      "FP =  14\n",
      "FN =  16\n",
      "\n",
      "Classifier type:  LSTM1\n",
      "MAE =  0.07649800709992102\n",
      "RMSE =  0.005935289881258486\n",
      "ACC =  0.5068493150684932\n",
      "AUC =  0.504524886877828\n",
      "SEN =  0.5384615384615384\n",
      "SPE =  0.47058823529411764\n",
      "TP =  21\n",
      "TN =  16\n",
      "FP =  18\n",
      "FN =  18\n",
      "\n",
      "Classifier type:  LSTM2\n",
      "MAE =  0.06857862469528433\n",
      "RMSE =  0.004782654004264152\n",
      "ACC =  0.5342465753424658\n",
      "AUC =  0.5282805429864253\n",
      "SEN =  0.6153846153846154\n",
      "SPE =  0.4411764705882353\n",
      "TP =  24\n",
      "TN =  15\n",
      "FP =  19\n",
      "FN =  15\n",
      "\n",
      "Classifier type:  LSTM3\n",
      "MAE =  0.07673084539552254\n",
      "RMSE =  0.0059711673359546195\n",
      "ACC =  0.547945205479452\n",
      "AUC =  0.5448717948717949\n",
      "SEN =  0.5897435897435898\n",
      "SPE =  0.5\n",
      "TP =  23\n",
      "TN =  17\n",
      "FP =  17\n",
      "FN =  16\n",
      "\n",
      "Classifier type:  LSTM4\n",
      "MAE =  0.07441028514640012\n",
      "RMSE =  0.005619842271605052\n",
      "ACC =  0.5068493150684932\n",
      "AUC =  0.5026395173453997\n",
      "SEN =  0.5641025641025641\n",
      "SPE =  0.4411764705882353\n",
      "TP =  22\n",
      "TN =  15\n",
      "FP =  19\n",
      "FN =  17\n",
      "\n",
      "Classifier type:  CNN-LSTM1\n",
      "MAE =  0.06715759197013059\n",
      "RMSE =  0.004583467500363447\n",
      "ACC =  0.4794520547945205\n",
      "AUC =  0.48076923076923084\n",
      "SEN =  0.46153846153846156\n",
      "SPE =  0.5\n",
      "TP =  18\n",
      "TN =  17\n",
      "FP =  17\n",
      "FN =  21\n",
      "\n",
      "Classifier type:  CNN-LSTM2\n",
      "MAE =  0.06529735355979949\n",
      "RMSE =  0.004333115531450063\n",
      "ACC =  0.410958904109589\n",
      "AUC =  0.41289592760180993\n",
      "SEN =  0.38461538461538464\n",
      "SPE =  0.4411764705882353\n",
      "TP =  15\n",
      "TN =  15\n",
      "FP =  19\n",
      "FN =  24\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       Model       MAE      RMSE    ACC (%)       AUC      SPEN       SPE\n0        SVR  0.064272  0.004198  46.575342  0.460407  0.538462  0.382353\n1       FFNN  0.076989  0.006037  58.904110  0.588989  0.589744  0.588235\n2      LSTM1  0.076498  0.005935  50.684932  0.504525  0.538462  0.470588\n3      LSTM2  0.068579  0.004783  53.424658  0.528281  0.615385  0.441176\n4      LSTM3  0.076731  0.005971  54.794521  0.544872  0.589744  0.500000\n5      LSTM4  0.074410  0.005620  50.684932  0.502640  0.564103  0.441176\n6  CNN-LSTM1  0.067158  0.004583  47.945205  0.480769  0.461538  0.500000\n7  CNN-LSTM2  0.065297  0.004333  41.095890  0.412896  0.384615  0.441176",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>MAE</th>\n      <th>RMSE</th>\n      <th>ACC (%)</th>\n      <th>AUC</th>\n      <th>SPEN</th>\n      <th>SPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVR</td>\n      <td>0.064272</td>\n      <td>0.004198</td>\n      <td>46.575342</td>\n      <td>0.460407</td>\n      <td>0.538462</td>\n      <td>0.382353</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FFNN</td>\n      <td>0.076989</td>\n      <td>0.006037</td>\n      <td>58.904110</td>\n      <td>0.588989</td>\n      <td>0.589744</td>\n      <td>0.588235</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LSTM1</td>\n      <td>0.076498</td>\n      <td>0.005935</td>\n      <td>50.684932</td>\n      <td>0.504525</td>\n      <td>0.538462</td>\n      <td>0.470588</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LSTM2</td>\n      <td>0.068579</td>\n      <td>0.004783</td>\n      <td>53.424658</td>\n      <td>0.528281</td>\n      <td>0.615385</td>\n      <td>0.441176</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LSTM3</td>\n      <td>0.076731</td>\n      <td>0.005971</td>\n      <td>54.794521</td>\n      <td>0.544872</td>\n      <td>0.589744</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LSTM4</td>\n      <td>0.074410</td>\n      <td>0.005620</td>\n      <td>50.684932</td>\n      <td>0.502640</td>\n      <td>0.564103</td>\n      <td>0.441176</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>CNN-LSTM1</td>\n      <td>0.067158</td>\n      <td>0.004583</td>\n      <td>47.945205</td>\n      <td>0.480769</td>\n      <td>0.461538</td>\n      <td>0.500000</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>CNN-LSTM2</td>\n      <td>0.065297</td>\n      <td>0.004333</td>\n      <td>41.095890</td>\n      <td>0.412896</td>\n      <td>0.384615</td>\n      <td>0.441176</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Entries:  9\n",
      "\n",
      "Classifier type:  SVR\n",
      "MAE =  0.06351511560001902\n",
      "RMSE =  0.0041044610473757485\n",
      "ACC =  0.4383561643835616\n",
      "AUC =  0.4366515837104073\n",
      "SEN =  0.46153846153846156\n",
      "SPE =  0.4117647058823529\n",
      "TP =  18\n",
      "TN =  14\n",
      "FP =  20\n",
      "FN =  21\n",
      "\n",
      "Classifier type:  FFNN\n",
      "MAE =  0.015749497353261484\n",
      "RMSE =  0.0003634571174030538\n",
      "ACC =  0.4931506849315068\n",
      "AUC =  0.4898190045248868\n",
      "SEN =  0.5384615384615384\n",
      "SPE =  0.4411764705882353\n",
      "TP =  21\n",
      "TN =  15\n",
      "FP =  19\n",
      "FN =  18\n",
      "\n",
      "Classifier type:  LSTM1\n",
      "MAE =  0.07683830129349815\n",
      "RMSE =  0.005986317870944667\n",
      "ACC =  0.4657534246575342\n",
      "AUC =  0.46417797888386125\n",
      "SEN =  0.48717948717948717\n",
      "SPE =  0.4411764705882353\n",
      "TP =  19\n",
      "TN =  15\n",
      "FP =  19\n",
      "FN =  20\n",
      "\n",
      "Classifier type:  LSTM2\n",
      "MAE =  0.07214191923486481\n",
      "RMSE =  0.00528837330207905\n",
      "ACC =  0.3150684931506849\n",
      "AUC =  0.3080693815987934\n",
      "SEN =  0.41025641025641024\n",
      "SPE =  0.20588235294117646\n",
      "TP =  16\n",
      "TN =  7\n",
      "FP =  27\n",
      "FN =  23\n",
      "\n",
      "Classifier type:  LSTM3\n",
      "MAE =  0.07826115115484937\n",
      "RMSE =  0.0062084529518559705\n",
      "ACC =  0.3287671232876712\n",
      "AUC =  0.3227752639517345\n",
      "SEN =  0.41025641025641024\n",
      "SPE =  0.23529411764705882\n",
      "TP =  16\n",
      "TN =  8\n",
      "FP =  26\n",
      "FN =  23\n",
      "\n",
      "Classifier type:  LSTM4\n",
      "MAE =  0.08077039071247645\n",
      "RMSE =  0.006607611607525451\n",
      "ACC =  0.3972602739726027\n",
      "AUC =  0.4019607843137255\n",
      "SEN =  0.3333333333333333\n",
      "SPE =  0.47058823529411764\n",
      "TP =  13\n",
      "TN =  16\n",
      "FP =  18\n",
      "FN =  26\n",
      "\n",
      "Classifier type:  CNN-LSTM1\n",
      "MAE =  0.06790139994321903\n",
      "RMSE =  0.004685104174169075\n",
      "ACC =  0.4657534246575342\n",
      "AUC =  0.46417797888386125\n",
      "SEN =  0.48717948717948717\n",
      "SPE =  0.4411764705882353\n",
      "TP =  19\n",
      "TN =  15\n",
      "FP =  19\n",
      "FN =  20\n",
      "\n",
      "Classifier type:  CNN-LSTM2\n",
      "MAE =  0.06383766480610438\n",
      "RMSE =  0.0041500469610237815\n",
      "ACC =  0.4520547945205479\n",
      "AUC =  0.4494720965309201\n",
      "SEN =  0.48717948717948717\n",
      "SPE =  0.4117647058823529\n",
      "TP =  19\n",
      "TN =  14\n",
      "FP =  20\n",
      "FN =  20\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "       Model       MAE      RMSE    ACC (%)       AUC      SPEN       SPE\n0        SVR  0.063515  0.004104  43.835616  0.436652  0.461538  0.411765\n1       FFNN  0.015749  0.000363  49.315068  0.489819  0.538462  0.441176\n2      LSTM1  0.076838  0.005986  46.575342  0.464178  0.487179  0.441176\n3      LSTM2  0.072142  0.005288  31.506849  0.308069  0.410256  0.205882\n4      LSTM3  0.078261  0.006208  32.876712  0.322775  0.410256  0.235294\n5      LSTM4  0.080770  0.006608  39.726027  0.401961  0.333333  0.470588\n6  CNN-LSTM1  0.067901  0.004685  46.575342  0.464178  0.487179  0.441176\n7  CNN-LSTM2  0.063838  0.004150  45.205479  0.449472  0.487179  0.411765",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Model</th>\n      <th>MAE</th>\n      <th>RMSE</th>\n      <th>ACC (%)</th>\n      <th>AUC</th>\n      <th>SPEN</th>\n      <th>SPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>SVR</td>\n      <td>0.063515</td>\n      <td>0.004104</td>\n      <td>43.835616</td>\n      <td>0.436652</td>\n      <td>0.461538</td>\n      <td>0.411765</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>FFNN</td>\n      <td>0.015749</td>\n      <td>0.000363</td>\n      <td>49.315068</td>\n      <td>0.489819</td>\n      <td>0.538462</td>\n      <td>0.441176</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>LSTM1</td>\n      <td>0.076838</td>\n      <td>0.005986</td>\n      <td>46.575342</td>\n      <td>0.464178</td>\n      <td>0.487179</td>\n      <td>0.441176</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>LSTM2</td>\n      <td>0.072142</td>\n      <td>0.005288</td>\n      <td>31.506849</td>\n      <td>0.308069</td>\n      <td>0.410256</td>\n      <td>0.205882</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>LSTM3</td>\n      <td>0.078261</td>\n      <td>0.006208</td>\n      <td>32.876712</td>\n      <td>0.322775</td>\n      <td>0.410256</td>\n      <td>0.235294</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>LSTM4</td>\n      <td>0.080770</td>\n      <td>0.006608</td>\n      <td>39.726027</td>\n      <td>0.401961</td>\n      <td>0.333333</td>\n      <td>0.470588</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>CNN-LSTM1</td>\n      <td>0.067901</td>\n      <td>0.004685</td>\n      <td>46.575342</td>\n      <td>0.464178</td>\n      <td>0.487179</td>\n      <td>0.441176</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>CNN-LSTM2</td>\n      <td>0.063838</td>\n      <td>0.004150</td>\n      <td>45.205479</td>\n      <td>0.449472</td>\n      <td>0.487179</td>\n      <td>0.411765</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "# Testing models\n",
    "index_model = 0\n",
    "for entry in entries:\n",
    "    print (\"# Entries: \", entry)\n",
    "    feature_mtx, label_mtx, class_label_mtx = generate_feat_labels_per_horizon(entry, df)\n",
    "    scaler_input = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_input.fit(feature_mtx)\n",
    "    train_idx = lastday_2017 - entry\n",
    "    test_x = feature_mtx[train_idx:]\n",
    "    test_y = label_mtx[train_idx:]\n",
    "    \n",
    "    model_list = []\n",
    "    MAE_list = []\n",
    "    RMSE_list = []\n",
    "    ACC_list = []\n",
    "    AUC_list = []\n",
    "    SEN_list = []\n",
    "    SPE_list = []\n",
    "    \n",
    "    for i in range(index_model, index_model+8):\n",
    "        test_y_estimative = models[i].predict(test_x)\n",
    "        tp, tn, fp, fn, auc_value = get_metrics(test_y, test_y_estimative)\n",
    "        \n",
    "        print(\"\\nClassifier type: \", labels[i])\n",
    "        print(\"MAE = \", mean_absolute_error(test_y, test_y_estimative))\n",
    "        print(\"RMSE = \", mean_squared_error(test_y, test_y_estimative, squared=True))\n",
    "        print(\"ACC = \", (tp + tn) / (tp + tn + fp + fn))\n",
    "        print(\"AUC = \", auc_value)\n",
    "        print(\"SEN = \", tp / (tp + fn))\n",
    "        print(\"SPE = \", tn / (tn + fp))\n",
    "        print(\"TP = \", tp)\n",
    "        print(\"TN = \", tn)\n",
    "        print(\"FP = \", fp)\n",
    "        print(\"FN = \", fn)\n",
    "        \n",
    "        model_list.append(labels[i])\n",
    "        MAE_list.append(mean_absolute_error(test_y, test_y_estimative))\n",
    "        RMSE_list.append(mean_squared_error(test_y, test_y_estimative, squared=True))\n",
    "        ACC_list.append(((tp + tn) / (tp + tn + fp + fn))*100)\n",
    "        AUC_list.append(auc_value)\n",
    "        SEN_list.append(tp / (tp + fn))\n",
    "        SPE_list.append(tn / (tn + fp))\n",
    "        \n",
    "    df_print = pd.DataFrame(list(zip(model_list, MAE_list,RMSE_list,ACC_list,AUC_list,SEN_list, SPE_list)),\n",
    "           columns =['Model', 'MAE', 'RMSE', 'ACC (%)', 'AUC', 'SPEN', 'SPE'])\n",
    "    df_print.style\n",
    "    display(df_print)\n",
    "        \n",
    "    index_model += 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f87398b2de8e90719949ed00c7b022e62357d5ca27b768fb93eb54116fa5b864"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('CNN-LSTM_gold_price-o7kuqWqa': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}