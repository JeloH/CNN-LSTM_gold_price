{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Conv1D, MaxPooling1D, InputLayer\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Dataset shape:  (1089, 7)\nDate          object\nOpen         float64\nHigh         float64\nLow          float64\nClose        float64\nAdj Close    float64\nVolume       float64\ndtype: object\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "         Date         Open         High          Low        Close  \\\n",
       "0  2013-12-31  1196.400024  1212.400024  1182.000000  1201.900024   \n",
       "1  2014-01-02  1204.300049  1227.300049  1204.300049  1225.000000   \n",
       "2  2014-01-03  1221.699951  1239.000000  1221.699951  1238.400024   \n",
       "3  2014-01-06  1232.800049  1247.000000  1221.900024  1237.800049   \n",
       "4  2014-01-07  1239.300049  1242.400024  1226.300049  1229.400024   \n",
       "\n",
       "     Adj Close  Volume  \n",
       "0  1201.900024   124.0  \n",
       "1  1225.000000   209.0  \n",
       "2  1238.400024   142.0  \n",
       "3  1237.800049   127.0  \n",
       "4  1229.400024    73.0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Date</th>\n      <th>Open</th>\n      <th>High</th>\n      <th>Low</th>\n      <th>Close</th>\n      <th>Adj Close</th>\n      <th>Volume</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2013-12-31</td>\n      <td>1196.400024</td>\n      <td>1212.400024</td>\n      <td>1182.000000</td>\n      <td>1201.900024</td>\n      <td>1201.900024</td>\n      <td>124.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2014-01-02</td>\n      <td>1204.300049</td>\n      <td>1227.300049</td>\n      <td>1204.300049</td>\n      <td>1225.000000</td>\n      <td>1225.000000</td>\n      <td>209.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2014-01-03</td>\n      <td>1221.699951</td>\n      <td>1239.000000</td>\n      <td>1221.699951</td>\n      <td>1238.400024</td>\n      <td>1238.400024</td>\n      <td>142.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2014-01-06</td>\n      <td>1232.800049</td>\n      <td>1247.000000</td>\n      <td>1221.900024</td>\n      <td>1237.800049</td>\n      <td>1237.800049</td>\n      <td>127.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2014-01-07</td>\n      <td>1239.300049</td>\n      <td>1242.400024</td>\n      <td>1226.300049</td>\n      <td>1229.400024</td>\n      <td>1229.400024</td>\n      <td>73.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 69
    }
   ],
   "source": [
    "# Reading the dataset\n",
    "data_csv = \"dataset.csv\"\n",
    "df = pd.read_csv(data_csv)\n",
    "print('Dataset shape: ', df.shape)\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "     Open  High  Low  Close  Adj Close  Volume\n127   NaN   NaN  NaN    NaN        NaN     NaN\n230   NaN   NaN  NaN    NaN        NaN     NaN\n248   NaN   NaN  NaN    NaN        NaN     NaN\n515   NaN   NaN  NaN    NaN        NaN     NaN\n535   NaN   NaN  NaN    NaN        NaN     NaN\nDataset shape:  (1081, 7)\n"
     ]
    }
   ],
   "source": [
    "# Verifying null values and deleting name from dataset\n",
    "null_columns=df.columns[df.isnull().any()]\n",
    "print(df[df.isnull().any(axis=1)][null_columns].head())\n",
    "# Drop the lines with null values\n",
    "df = df.dropna()\n",
    "# Drop Date column\n",
    "# df.pop(\"Date\")\n",
    "\n",
    "print('Dataset shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Minimum: 1046.199951\n",
      "Maximum: 1391.400024\n",
      "Mean: 1239.990934614246\n",
      "Median: 1251.0\n",
      "SD: 72.09937994027128\n",
      "Skewness: -0.5455305158449637\n",
      "Kurtosis: -0.3520037164214358\n"
     ]
    }
   ],
   "source": [
    "print(\"Minimum: {}\\nMaximum: {}\\nMean: {}\\nMedian: {}\\nSD: {}\\nSkewness: {}\\nKurtosis: {}\".format(df[\"Low\"].min(), df[\"High\"].max(), \n",
    "df[\"Open\"].mean(), df[\"Open\"].median(), df[\"Open\"].std(), df[\"Open\"].skew(), df[\"Open\"].kurtosis()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train:  (1007,) Test:  (74,)\n"
     ]
    }
   ],
   "source": [
    "lastday_2017 = df.loc[df[\"Date\"]==\"2017-12-29\"].index.values[0]\n",
    "df = df[\"Close\"].values\n",
    "\n",
    "# Transforming the dataset to ln scale\n",
    "df = np.log(df)\n",
    "\n",
    "# # Split dataset into train and test\n",
    "train_set = df[0:lastday_2017]\n",
    "test_set = df[lastday_2017:]\n",
    "print(\"Train: \", train_set.shape, \"Test: \", test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1007"
      ]
     },
     "metadata": {},
     "execution_count": 73
    }
   ],
   "source": [
    "lastday_2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# df   = df.reshape(len(df),1)\n",
    "# scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "# scaler.fit(df)\n",
    "# df = scaler.transform(df).flatten()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labels of an LSTM network\n",
    "Now for the labels of the LSTM network, not all the cases require a label matrix of 3 dimensions. The cases where this is required are on sequence to sequence problems, where the model is made to predict a sequence of timestamps of one or more features. However for our problem, the LSTM network needs to predict the next day gold price closing value, this way a matrix of 2 dimensions will suffice for this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FFNN class\n",
    "class FFNN:\n",
    "    def __init__(self, input_dim, scaler=None):\n",
    "        self.scaler = scaler \n",
    "        optimizer = Adam()\n",
    "        h_n = 3 if input_dim == 4 or input_dim == 6 else 5\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(h_n, input_dim=input_dim))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=[\"accuracy\", \"mean_absolute_error\"])\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        if self.scaler:\n",
    "            x_train = self.scaler.transform(x_train)\n",
    "            y_train = self.scaler.transform(y_train)\n",
    "        self.model.fit(x_train, y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=128,\n",
    "                        verbose=0\n",
    "                      )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        if self.scaler:\n",
    "            x_test = self.scaler.transform(x_test)\n",
    "            \n",
    "        y_valid_pred = self.model.predict(x_test)\n",
    "        \n",
    "        if self.scaler:\n",
    "            y_valid_pred = self.scaler.transform(y_valid_pred)\n",
    "\n",
    "        return y_valid_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM class\n",
    "class PLSTM:\n",
    "    def __init__(self, input_shape, model_type, scaler=None):\n",
    "        self.scaler = scaler \n",
    "        optimizer = Adam()\n",
    "        self.model = Sequential()\n",
    "        self.h_n1 = 100 if model_type in [1,3,4] else 200\n",
    "        return_seq = True if model_type>2 else False\n",
    "        self.model.add(LSTM(units=self.h_n1, input_shape=(input_shape[1], 1), return_sequences=return_seq))\n",
    "        if model_type>2:\n",
    "            self.h_n2 = 50 if model_type == 3 else 100\n",
    "            self.model.add(LSTM(units=self.h_n2))\n",
    "            if type==4:\n",
    "                self.model.add(Dense(32))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss=\"mean_squared_error\", optimizer=optimizer, metrics=[\"accuracy\", \"mean_absolute_error\"])\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        if self.scaler:\n",
    "            x_train = self.scaler.transform(x_train)\n",
    "            y_train = self.scaler.transform(y_train)\n",
    "\n",
    "        # reshape the entry as a 3D matrix with samples, timestamps and lastly features\n",
    "        # instead of only samples and features as usual.\n",
    "        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "        history = self.model.fit(x_train, y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=128,\n",
    "                        verbose=0)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        if self.scaler:\n",
    "            x_test = self.scaler.transform(x_test)\n",
    "        print(x_test.shape)\n",
    "        print(self.model.summary())\n",
    "        y_valid_pred = self.model.predict(x_test)\n",
    "        \n",
    "        if self.scaler:\n",
    "            y_valid_pred = self.scaler.transform(y_valid_pred)\n",
    "\n",
    "        return y_valid_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN-LSTM class\n",
    "class CNNLSTM:\n",
    "    def __init__(self, input_shape, model_type, scaler=None):\n",
    "        self.scaler = scaler\n",
    "        optimizer = Adam()\n",
    "        self.model = Sequential()\n",
    "        self.h_n1 = 100 if model_type == 1 else 200\n",
    "        self.filter1 = 32 if model_type == 1 else 64\n",
    "        self.filter2 = 64 if model_type == 1 else 128\n",
    "        \n",
    "        self.model.add(Conv1D(self.filter1, 2,activation='relu',\n",
    "                       strides=1,\n",
    "                       padding='same',\n",
    "                       input_shape=(input_shape[1],\n",
    "                                   1)))\n",
    "\n",
    "        self.model.add(Conv1D(self.filter2, 2,\n",
    "                   activation='relu',\n",
    "                   strides=1,\n",
    "                   padding='same',\n",
    "                   input_shape=(input_shape[1],\n",
    "                                1)))\n",
    "\n",
    "        self.model.add(MaxPooling1D(pool_size=2, padding='valid'))\n",
    "        self.model.add(LSTM(units=self.h_n1, input_shape=(input_shape[1],1)))\n",
    "    \n",
    "        if type==2:\n",
    "            self.model.add(Dense(32))\n",
    "        self.model.add(Dense(1))\n",
    "        self.model.compile(loss=\"mean_squared_error\", optimizer=optimizer)\n",
    "    \n",
    "    def fit(self,x_train,y_train):\n",
    "        if self.scaler:\n",
    "            x_train = self.scaler.transform(x_train)\n",
    "            y_train = self.scaler.transform(y_train)\n",
    "            \n",
    "        # reshape the entry as a 3D matrix with samples, timestamps and lastly features\n",
    "        # instead of only samples and features as usual.\n",
    "        x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "        \n",
    "        self.model.fit(x_train, y_train,\n",
    "                        epochs=50,\n",
    "                        batch_size=128,\n",
    "                        verbose=0\n",
    "                      )\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        if self.scaler:\n",
    "            x_test = self.scaler.transform(x_test)\n",
    "            \n",
    "        x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "        y_valid_pred = self.model.predict(x_test)\n",
    "        \n",
    "        if self.scaler:\n",
    "            y_valid_pred = self.scaler.transform(y_valid_pred)\n",
    "\n",
    "        return y_valid_pred.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(entry_shape, scaler=None):\n",
    "    # SVR\n",
    "    svr = SVR(kernel='rbf', C=1, tol=1e-3)\n",
    "\n",
    "    # FFNN\n",
    "    ffnn = FFNN(entry_shape[1], scaler)\n",
    "\n",
    "    # LSTM1\n",
    "    lstm1 = PLSTM(entry_shape, 1, scaler)\n",
    "\n",
    "    # LSTM2\n",
    "    lstm2 = PLSTM(entry_shape, 2, scaler)\n",
    "\n",
    "    # LSTM3\n",
    "    lstm3 = PLSTM(entry_shape, 3, scaler)\n",
    "\n",
    "    # LSTM4\n",
    "    lstm4 = PLSTM(entry_shape, 4, scaler)\n",
    "\n",
    "    # CNN-LSTM1\n",
    "    cnnlstm1 = CNNLSTM(entry_shape, 1, scaler)\n",
    "\n",
    "    # CNN-LSTM2\n",
    "    cnnlstm2 = CNNLSTM(entry_shape, 2, scaler)\n",
    "\n",
    "    labels = [\"SVR\", \"FFNN\", \"LSTM1\", \"LSTM2\", \"LSTM3\", \"LSTM4\", \"CNN-LSTM1\", \"CNN-LSTM2\"]\n",
    "    models = [svr, ffnn, lstm1, lstm2, lstm3, lstm4, cnnlstm1, cnnlstm2]\n",
    "\n",
    "    return labels, models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling window approach\n",
    "The paper states that in order to predict the next day gold price, the model uses the $n$ past days gold prince, where $n$ stands for the time horizon used. Thus to generate a dataset with this specifications, we will use a rolling window algorithm to generate a window of features to a window of labels ( with in this case is equal to 1). This rolling window procedure works as follows:\n",
    "\n",
    "Features: $[n1, n2, n3, n4, n5]$ -> Label $[n6]$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_window_mtx(x, window_size):\n",
    "        \"\"\"Compute all overlapping (rolling) observation windows over a vector \n",
    "            and return a matrix\n",
    "\n",
    "        Args:\n",
    "            x           : observation vector that is supposed to be split into\n",
    "                          overlapping windows\n",
    "            window_size : the target window size\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            Window matrix with all windows as rows. That is, if n_windows is the\n",
    "            number of windows, the result has dimensions:\n",
    "\n",
    "            (n_windows, window_size)\n",
    "\n",
    "        \"\"\"\n",
    "        if window_size < 1:\n",
    "            raise ValueError(\"`window_size` must be at least 1.\")\n",
    "        if window_size > x.shape[-1]:\n",
    "            raise ValueError(\"`window_size` is too long.\")\n",
    "\n",
    "        shape = x.shape[:-1] + (x.shape[-1] - window_size + 1, window_size)\n",
    "        strides = x.strides + (x.strides[-1],)\n",
    "\n",
    "        return np.lib.stride_tricks.as_strided(x, shape=shape, strides=strides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feat_labels_per_horizon(time_horizon, df, verbose=False):\n",
    "\n",
    "    # Get the feature and label to the prediction task \n",
    "    feature_mtx = rolling_window_mtx(df, time_horizon)[:-1]\n",
    "    label_mtx   = rolling_window_mtx(df[time_horizon:], 1)\n",
    "    index_mtx   = rolling_window_mtx(np.arange(len(df)), time_horizon)\n",
    "\n",
    "    if verbose:\n",
    "        # Now we have a set of windows of the real coordinate\n",
    "        # Lets take a look in one window\n",
    "        print(f\"\\n One feature window: \\n {feature_mtx[0]}\")\n",
    "        print(f\"\\n One label window: \\n {label_mtx[0]}\")\n",
    "        print(f\"\\n Original dataset: \\n {df[0:5]}\")\n",
    "\n",
    "    # For the classification task (if the gold values goes up or down)\n",
    "    # We need to get a window of size 2, and then calculate the difference\n",
    "    # If positive, the gold value went up.\n",
    "    class_label_mtx = rolling_window_mtx(df[time_horizon-1:], 2)\n",
    "    func = lambda x: True if x > 0 else False\n",
    "    class_func = np.vectorize(func)\n",
    "    class_label_mtx = class_func(np.diff(class_label_mtx).flatten()).reshape(len(class_label_mtx),1)\n",
    "   \n",
    "    if verbose:\n",
    "    \n",
    "        print(f\"\\n One window of class label (If tomorrow price is larger than today's price): \\n {class_label_mtx[0]}\")\n",
    "    \n",
    "    return feature_mtx, label_mtx, class_label_mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_index_mtx = rolling_window_mtx(np.arange(len(df))[4:], 1)\n",
    "index_mtx   = rolling_window_mtx(np.arange(len(df)), 4)[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([1003, 1004, 1005, 1006]), array([1007]))"
      ]
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "train_idx = lastday_2017 - 4\n",
    "index_mtx[train_idx], label_index_mtx[train_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([7.09165894, 7.11069612, 7.12157552, ..., 7.18629566, 7.18258009,\n",
       "       7.1856143 ])"
      ]
     },
     "metadata": {},
     "execution_count": 83
    }
   ],
   "source": [
    "df = df.reshape(len(df),1)\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "scaler.fit(df)\n",
    "df = df.flatten()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "SVR\n",
      "FFNN\n",
      "/home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "LSTM1\n",
      "LSTM2\n",
      "LSTM3\n",
      "LSTM4\n",
      "CNN-LSTM1\n",
      "CNN-LSTM2\n",
      "SVR\n",
      "FFNN\n",
      "/home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "LSTM1\n",
      "LSTM2\n",
      "LSTM3\n",
      "LSTM4\n",
      "CNN-LSTM1\n",
      "CNN-LSTM2\n",
      "SVR\n",
      "FFNN\n",
      "/home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "LSTM1\n",
      "LSTM2\n",
      "LSTM3\n",
      "LSTM4\n",
      "CNN-LSTM1\n",
      "CNN-LSTM2\n"
     ]
    }
   ],
   "source": [
    "entries = [4, 6, 9]\n",
    "models = []\n",
    "labels = []\n",
    "for entry in entries:\n",
    "    #Creating dataset\n",
    "    feature_mtx, label_mtx, class_label_mtx = generate_feat_labels_per_horizon(entry, df)\n",
    "    scaler_input = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_input.fit(feature_mtx)\n",
    "    scaler_output = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_output.fit(label_mtx)\n",
    "    train_idx = lastday_2017 - entry\n",
    "    train_x = feature_mtx[:train_idx]\n",
    "    train_y = label_mtx[:train_idx]\n",
    "    tmp_labels, tmp_models = create_models(train_x.shape)#, scaler)\n",
    "    for i in range(len(tmp_models)):\n",
    "        print(tmp_labels[i])\n",
    "        tmp_models[i].fit(train_x, train_y)\n",
    "    models.append(tmp_models)\n",
    "    labels.append(tmp_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "models = np.ravel(models)\n",
    "labels = np.ravel(labels)\n",
    "print(len(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "# Entries:  4\n",
      "Classifier type:  SVR \n",
      "MAE =  0.07038084116745039 \n",
      "RMSE =  0.005027129598584784 \n",
      "\n",
      "Classifier type:  FFNN \n",
      "MAE =  0.013092204794938247 \n",
      "RMSE =  0.00024889729746867777 \n",
      "\n",
      "(74, 4)\n",
      "Model: \"sequential_64\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_72 (LSTM)               (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_74 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:219 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_64 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 4)\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-047195186da1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtest_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel_mtx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_model\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mtest_y_estimative\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Classifier type: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\nMAE = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_estimative\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\nRMSE = \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y_estimative\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mindex_model\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-76-0fa4695c885e>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x_test)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0my_valid_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1725\u001b[0m           \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_predict_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m             \u001b[0mtmp_batch_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m               \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    762\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    763\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 764\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3048\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3049\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3050\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3051\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3443\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3444\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3445\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3287\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3288\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3289\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3290\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3291\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    997\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 999\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1000\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1001\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    984\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1569 predict_function  *\n        return step_function(self, iterator)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1559 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:1285 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:2833 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/distribute/distribute_lib.py:3608 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1552 run_step  **\n        outputs = model.predict_step(data)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1525 predict_step\n        return self(x, training=False)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py:1013 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/cleversonahum/.local/share/virtualenvs/CNN-LSTM_gold_price-o7kuqWqa/lib/python3.7/site-packages/tensorflow/python/keras/engine/input_spec.py:219 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_64 is incompatible with the layer: expected ndim=3, found ndim=2. Full shape received: (None, 4)\n"
     ]
    }
   ],
   "source": [
    "# Testing models\n",
    "index_model = 0\n",
    "for entry in entries:\n",
    "    print (\"# Entries: \", entry)\n",
    "    feature_mtx, label_mtx, class_label_mtx = generate_feat_labels_per_horizon(entry, df)\n",
    "    scaler_input = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler_input.fit(feature_mtx)\n",
    "    train_idx = lastday_2017 - entry\n",
    "    test_x = feature_mtx[train_idx:]\n",
    "    test_y = label_mtx[train_idx:]\n",
    "    for i in range(index_model, index_model+8):\n",
    "        test_y_estimative = models[i].predict(test_x)\n",
    "        print(\"Classifier type: \", labels[i], \"\\nMAE = \", mean_absolute_error(test_y, test_y_estimative),\"\\nRMSE = \", mean_squared_error(test_y, test_y_estimative, squared=True), \"\\n\")\n",
    "    index_model += 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f87398b2de8e90719949ed00c7b022e62357d5ca27b768fb93eb54116fa5b864"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('CNN-LSTM_gold_price-o7kuqWqa': pipenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}